{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432db0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>:root { --jp-notebook-max-width: 100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "import importlib, numpy as np\n",
    "from sys import path\n",
    "import time, os, copy\n",
    "\n",
    "from sunpy.map import Map\n",
    "from sunpy.net import Fido, vso, attrs as a\n",
    "from sunpy.time import TimeRange\n",
    "from ndcube import NDCube, NDCubeSequence, NDCollection\n",
    "from astropy import wcs\n",
    "\n",
    "import astropy.units as u\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "\n",
    "plt.rcParams.update({'font.size': 18}) # Make the fonts in figures big enough for papers\n",
    "plt.rcParams.update({'figure.figsize':[27,15]})\n",
    "plt.rcParams.update({'image.origin':'lower'})\n",
    "np.set_printoptions(linewidth=128)\n",
    "\n",
    "base_path = os.getcwd()\n",
    "\n",
    "import EMToolKit.EMToolKit as emtk\n",
    "# from EMToolKit.visualization.dashboard import dashboard_figure\n",
    "from EMToolKit.instruments.aia import load_from_paths, aia_wrapper\n",
    "from EMToolKit.instruments.xrt import xrt_wrapper\n",
    "from EMToolKit.algorithms.sparse_em_wrapper import sparse_em_wrapper\n",
    "from EMToolKit.algorithms.simple_reg_dem_wrapper import simple_reg_dem_wrapper\n",
    "from EMToolKit.algorithms.sparse_nlmap_dem_wrapper import sparse_nlmap_dem_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9b107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import EMToolKit\n",
    "import EMToolKit.visualization\n",
    "importlib.reload(EMToolKit)\n",
    "importlib.reload(EMToolKit.visualization)\n",
    "# importlib.reload(EMToolKit.visualization.dashboard)\n",
    "import EMToolKit.EMToolKit as emtk\n",
    "# from EMToolKit.visualization.dashboard import dashboard_figure\n",
    "em_collection=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5783f36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "daystr = '20100725'\n",
    "date='2010/07/25 17:58:44'\n",
    "data_path = os.path.join(base_path,'../data',daystr)\n",
    "\n",
    "xl, yl, dx, dy = 240*u.arcsec, -525*u.arcsec, 270*u.arcsec, 240*u.arcsec\n",
    "#xl, yl, dx, dy = 240*u.arcsec, -525*u.arcsec, 135*u.arcsec, 120*u.arcsec\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "paths = [data_path + pth for pth in os.listdir(data_path)\n",
    "         if (os.path.isfile(os.path.join(data_path, pth)) and \".fits\" in pth)]\n",
    "print(f\"Searching for images from {date}...\")\n",
    "\n",
    "redownload = False\n",
    "if len(paths) < 7 or redownload:\n",
    "# Commands for initial data download. Comment out once that's successful.\n",
    "# VSO can sometimes be a bit flakey here, in my experience, may require multiple tries:\n",
    "    print(f\"Only {len(paths)} of 7 images found, searching FIDO...\")\n",
    "    dl_paths = []\n",
    "    passbands = np.array([94,131,171,193,211,335])*u.angstrom\n",
    "\n",
    "    # Combine the wavelength queries using the | operator\n",
    "    wavelength_query = a.Wavelength(passbands[0])\n",
    "    for band in passbands[1:]:\n",
    "        wavelength_query |= a.Wavelength(band)\n",
    "\n",
    "    qry = Fido.search(a.Time(TimeRange(date,11.8*u.s)),a.Instrument('AIA')|a.Instrument('XRT'),wavelength_query)\n",
    "\n",
    "    print(f\"Downloading {len(qry)} images from AIA...\")\n",
    "    Fido.fetch(qry,path=data_path, max_conn=len(passbands)+1)\n",
    "\n",
    "    qry = Fido.search(a.Time(TimeRange(date,4*u.s)), a.Instrument('XRT'))\n",
    "    print(f\"Downloading {len(qry)} images from XRT...\")\n",
    "    Fido.fetch(qry,path=data_path, max_conn=len(passbands)+1)\n",
    "else:\n",
    "    print(f\"Found {len(paths)} images, skipping download.\")\n",
    "\n",
    "\n",
    "paths = sorted([os.path.abspath(os.path.join(data_path,pth)) for pth in os.listdir(data_path)\n",
    "         if (os.path.isfile(os.path.join(data_path, pth)) and \".fits\" in pth)])\n",
    "\n",
    "channel_names = sorted(np.array(['AIA94_THIN', 'AIA131_THIN', 'AIA171_THIN', 'AIA193_THIN', 'AIA211_THIN', 'AIA335_THIN', 'XRT']))\n",
    "\n",
    "hinode_path = paths[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3597b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiapaths = paths[0:6]\n",
    "\n",
    "aiamaps = load_from_paths(paths[0:6],xl=xl,yl=yl,dx=dx,dy=dy)\n",
    "# We're loading these separately so that we can apply an offset to the XRT data -- there appears\n",
    "# to be a significant misalignment based on manual inspection and testing:\n",
    "#xrt_offsets = [-2*u.arcsec, -11*u.arcsec]\n",
    "#xrt_offsets = [-7*u.arcsec, -23*u.arcsec]\n",
    "xrt_offsets = [-5*u.arcsec, -20*u.arcsec]\n",
    "# xrtmap = load_from_paths(paths[-1],xl=xl+xrt_offsets[0],yl=yl+xrt_offsets[1],dx=dx,dy=dy)[1]\n",
    "xrtmap = load_from_paths([[paths[0]],hinode_path],xl=xl+xrt_offsets[0],yl=yl+xrt_offsets[1],dx=dx,dy=dy)[1]\n",
    "\n",
    "xrtmap.meta['crval1'] -= xrt_offsets[0].value\n",
    "xrtmap.meta['crval2'] -= xrt_offsets[1].value\n",
    "\n",
    "[xrtmaps,xrterrs,xrt_trlogts,xrt_tresps] = xrt_wrapper([xrtmap])\n",
    "[maps,errs,trlogts,tresps] = aia_wrapper(aiamaps)\n",
    "maps.append(xrtmaps[0])\n",
    "errs.append(xrterrs[0])\n",
    "trlogts.append(xrt_trlogts[0])\n",
    "tresps.append(xrt_tresps[0])\n",
    "\n",
    "logt = np.linspace(5.5,7.5,41)\n",
    "for i in range(0,len(tresps)):\n",
    "\ttresps[i] = np.interp(logt,trlogts[i],tresps[i])\n",
    "\ttrlogts[i] = copy.deepcopy(logt)\n",
    "\n",
    "# Normalizing the response functions makes them much easier for the solver to handle.\n",
    "datmax_nominal = 1.0e4 # The nominal maximum of the data\n",
    "overall_norm = datmax_nominal/np.max(np.array(tresps))\n",
    "norms = np.max(np.array(tresps),axis=0)/np.max(np.array(tresps))/overall_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d9e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data sequence from AIA & XRT data:\n",
    "datasequence = emtk.em_data(maps,errs,trlogts,tresps)\n",
    "\n",
    "# Create em_collection with AIA & XRT data:\n",
    "em_collection = emtk.em_collection(datasequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6b296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some of the AIA channels and their temperature responses for illustration:\n",
    "plt_emmax = 5.0e28\n",
    "gfac = 1.0/2.2\n",
    "\n",
    "fig, axs = plt.subplots(2, 3)\n",
    "axs[0,0].imshow(np.clip(maps[1].data/np.max(tresps[1]),0,plt_emmax)**gfac,cmap=plt.get_cmap('gray'))\n",
    "axs[0,0].set(title='AIA 193 Angstrom')\n",
    "axs[1,0].plot(trlogts[1],tresps[1]/1.0e-27)\n",
    "axs[1,0].set(title='AIA 193 Temperature Response',xlabel='Temperature (dB Kelvin)',ylabel='Response (DN/s/(10$^9$ cm$^{-3})^2$/Mm)')\n",
    "\n",
    "axs[0,1].imshow(np.clip(maps[2].data/np.max(tresps[2]),0,plt_emmax)**gfac,cmap=plt.get_cmap('gray'))\n",
    "axs[0,1].set(title='AIA 335 Angstrom')\n",
    "axs[1,1].plot(trlogts[2],tresps[2]/1.0e-27)\n",
    "axs[1,1].set(title='AIA 335 Temperature Response',xlabel='Temperature (dB Kelvin)',ylabel='Response (DN/s/(cm$^{-3})^2$/Mm)')\n",
    "\n",
    "axs[0,2].imshow(np.clip(maps[5].data/np.max(tresps[5]),0,plt_emmax)**gfac,cmap=plt.get_cmap('gray'))\n",
    "axs[0,2].set(title='AIA 94 Angstrom')\n",
    "axs[1,2].plot(trlogts[5],tresps[5]/1.0e-27)\n",
    "axs[1,2].set(title='AIA 94 Temperature Response',xlabel='Temperature (dB Kelvin)',ylabel='Response (DN/s/(cm$^{-3})^2$/Mm)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3828a08f-77fd-4c6b-9688-3d14164bd9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make DEM sequence from the DEM and add it to the collection:\n",
    "multi_out = sparse_nlmap_dem_wrapper(datasequence, wrapargs={'norms':norms, 'overall_norm':overall_norm})\n",
    "multi_em_demsequence = emtk.dem_model(*multi_out)\n",
    "em_collection.add_model(multi_em_demsequence)\n",
    "\n",
    "# Unpack the output\n",
    "multi_coeffs, multi_logts, multi_bases, multi_coords, multi_algorithm, multi_em_wrapper = multi_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8480551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(type((collect)))\n",
    "# # collect_dict = dict(collect)\n",
    "# # print(collect_dict.keys())\n",
    "# # print(collect_dict[\"data\"])\n",
    "\n",
    "\n",
    "# import asdf\n",
    "# from ndcube import NDCollection\n",
    "\n",
    "# # Your NDCollection\n",
    "# my_ndcollection = collect\n",
    "\n",
    "# # Create a new ASDF file\n",
    "# with asdf.AsdfFile() as af:\n",
    "#     # Iterate over items in the NDCollection and add them to the ASDF file\n",
    "#     # print(my_ndcollection['models'])\n",
    "\n",
    "#     af['data'] = []\n",
    "#     af['meta_keys'] = []\n",
    "#     af['meta_values'] = []\n",
    "#     af['methods'] = []\n",
    "#     for img in my_ndcollection['data']:\n",
    "#         af['data'].append(img.data)\n",
    "#         img_meta = copy.copy(img.meta)\n",
    "#         # schema = img_meta[\"schema\"]\n",
    "#         # del img_meta[\"schema\"]\n",
    "#         # print (img_meta)\n",
    "#         af['meta_keys'].append(img_meta.keys())\n",
    "#         af['meta_values'].append(img_meta.values())\n",
    "\n",
    "#     for mthd in my_ndcollection['models']:\n",
    "#         af['methods'].append(mthd)\n",
    "#         # af['method_meta'].append(([key, value] for key, value in mthd.meta.items()))\n",
    "\n",
    "#     for key, ndcube in my_ndcollection.items():\n",
    "#         # Here, 'key' can be used to uniquely identify each NDCube in the collection\n",
    "#         # print (dir(ndcube))\n",
    "#         # af[key] = {\n",
    "#         #     'data': ,\n",
    "#         #     # 'meta': ndcube.meta\n",
    "#         # }\n",
    "#         pass\n",
    "#         # print(key)\n",
    "#         # print((my_ndcollection[key]))\n",
    "#     # Write the ASDF file to disk\n",
    "#     af.write_to(f'{data_path}/my_ndcollection.fits')\n",
    "\n",
    "\n",
    "# # print(collect_dict['data'][0].wcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ff869f-2c80-4611-a047-c2f928fb1359",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53c3d1b-407b-4030-952e-68a45e1f21cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_synthmaps = [em_collection.synthesize_map(map) for map in em_collection.data()]\n",
    "multi_synthdata = [map for map in multi_synthmaps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8005dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_resids(synthdata, em_collection):# Calculate the residuals and Chi squared:\n",
    "\tndata = len(synthdata)\n",
    "\tresids = []\n",
    "\tdatasequence = em_collection.data()\n",
    "\tchi2 = 0\n",
    "\t[nx,ny] = datasequence[0].data.shape\n",
    "\tfor seq in datasequence: [nx,ny] = [np.min([seq.data.shape[0],nx]),np.min([seq.data.shape[1],ny])]\n",
    "\tfor i in range(0,ndata):\n",
    "\t\tresids.append(((synthdata[i].data-datasequence[i].data)/datasequence[i].uncertainty.array)**2)\n",
    "\t\tchi2 += np.mean(resids[i])/ndata\n",
    "\treturn resids, chi2\n",
    "\n",
    "#spars_resids, spars_chi2 = calc_resids(spars_synthdata,em_collection)\n",
    "#simpl_resids, simpl_chi2 = calc_resids(simpl_synthdata,em_collection)\n",
    "multi_resids, multi_chi2 = calc_resids(multi_synthdata,em_collection)\n",
    "print(\"Multi-instrument Chi squared = \",multi_chi2)\n",
    "#print('simple_reg_dem Chi squared = ',simpl_chi2, 'spars_em Chi squared = ',spars_chi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3ed125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Residuals:\n",
    "fig = plt.figure(figsize=[20,12])\n",
    "plt.suptitle('Residuals for '+multi_algorithm)\n",
    "for i in range(0,7):\n",
    "    ax1 = fig.add_subplot(2,4,i+1)\n",
    "    ax1.imshow(multi_resids[i],vmin=0,vmax=5)\n",
    "    ax1.set(title=em_collection.data()[i].meta['channel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bcd063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "# Get the most recent version from the tool kit:\n",
    "from EMToolKit.visualization.dashboard import dashboard_object\n",
    "importlib.reload(EMToolKit.visualization.dashboard)\n",
    "from EMToolKit.visualization.dashboard import dashboard_object\n",
    "\n",
    "# Create the dashboard:\n",
    "dash = dashboard_object(em_collection)\n",
    "dash.display()\n",
    "\n",
    "\n",
    "# class dashboard_object(object):\n",
    "#     def __init__(self,em_collection):\n",
    "#         self.emc = em_collection\n",
    "\n",
    "#     def widgwrap(self, xpt, ypt, rtemp, gtemp, btemp, sigma, algorithm):\n",
    "#         dashboard_figure(self.emc, plotpoint=[xpt,ypt], temperatures=[rtemp,gtemp,btemp], sigmas=sigma, algorithm=algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcf6d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(EMToolKit.visualization.dashboard)\n",
    "# from EMToolKit.visualization.dashboard import dashboard_figure\n",
    "# dash = dashboard_object(em_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c296f04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [nx,ny] = dash.emc.collection[dash.emc.collection['models'][0]][0].data.shape\n",
    "# xpt=widgets.IntSlider(min=0, max=nx, value=10, step=1, description='xpt', continuous_update=False)\n",
    "# ypt=widgets.IntSlider(min=0, max=ny, value=100, step=1, description='ypt', continuous_update=False)\n",
    "# rtemp=widgets.FloatSlider(min=5, max=7, value=5.8, step=0.05, description='rtemp', continuous_update=False)\n",
    "# gtemp=widgets.FloatSlider(min=5, max=7, value=6.1, step=0.05, description='gtemp', continuous_update=False)\n",
    "# btemp=widgets.FloatSlider(min=5, max=7, value=6.4, step=0.05, description='btemp', continuous_update=False)\n",
    "# sigma=widgets.FloatSlider(min=0.025, max=0.5, value=0.125, step=0.01, description='sigma', continuous_update=False)\n",
    "# algorithm=widgets.Dropdown(options=dash.emc.collection['models'], description='algorithm', continuous_update=False)\n",
    "# ui = widgets.HBox([xpt,ypt,rtemp,gtemp,btemp,sigma,algorithm])\n",
    "# out = widgets.interactive_output(dash.widgwrap, {'xpt':xpt,'ypt':ypt,'rtemp':rtemp,'gtemp':gtemp,'btemp':btemp,'sigma':sigma,'algorithm':algorithm})\n",
    "# display(ui,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a27721d-f578-4605-8cdc-c8b5133093b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
